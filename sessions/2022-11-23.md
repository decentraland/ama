2022-11-23: SDK

Questions

Q: When will the latest SDK editor come up, are you aiming at 0 codings developing in the future? If so,  when Beta test?

R:


Q: It‚Äôs difficult to invite people to a live event because they are all directed to different realms. Is there a way to fix it?

R:


Q: The voice chat doesn‚Äôt always work for every user: usually when this happens, who can‚Äôt speak can‚Äôt listen either. Are you going to improve the voice chat?

R:


Q: Is there a way to grant access to certain areas only to those owning a specific token?

R: Yes, it's possible. Check out this example from the Awesome Repository that does exactly that: https://github.com/decentraland-scenes/dcl-access-library


Q: Are there any plans to finish writing the RFCs? Especially the scene definitions that are marked as TODO.

R: Yes, it's an ongoing initiative, we've started to put a lot more focus on code-contributor facing documentation lately. We still need to catch up with some of that pending writing, but it will get done.


Q: Did you see my comments on working from specs on my blog? Are there any plans to start working that way?

R:


Q: Are there any plans of implementing real time sound synthesis and deeper functionality for audio in SDK besides sample playback? 

R: Not in the short term, it's not in the Foundation's plan right now, but it's absolutely an interesting project. External contribututions regarding this would be welcome.


Q: Can you open Decentraland voice chat for creative use and modification as well ? 

R: Not in the Foundation's current plans, but it should be possible. Player privacy should be taken into account here, surely there should need to be a permission added to the scene's permission. External contribututions regarding this would be welcome.


Q: Can the SDK access the user's microphone independent of the voice chat system? If not, any plans?

R: Not in the Foundation's current plans, but it should be possible. Player privacy should be taken into account here, surely there should need to be a permission added to the scene's permission. External contribututions regarding this would be welcome.


Q: Can SDK extract voice (avatars speak) ? I would like to make a robot using voice chat to communicate with visitors, which requires voice data. 

R: Not in the Foundation's current plans, but it should be possible. Player privacy should be taken into account here, surely there should need to be a permission added to the scene's permission. External contribututions regarding this would be welcome.


Q: Is there a patch note/list that is posted whenever new ecs or other updates occur? 

R: We will keep informing in Discord, in the SDK Announcements, whenever an update is released. Admittedly some minor releases were not announced there, we should be more consistent on that. You can also find this information in the [Github repo](https://github.com/decentraland/js-sdk-toolchain/releases).


Q: Will we ever get access to manipulate player controls such as gravity, avatar scale, and/or custom (not published) animations/emotes for game makers?

R: Yes, that should all be possible in the future. Allowing the player to perform custom animations is part of the roadmap for next quarter.


Q: In SDK 7 will there be a different way to add custom components? How will it differ?

R: Yes, the syntax on SDK7 will have significant changes. This is all fully documented, to be shared with the alpha release of the new SDK. Components are no longer objects, that may have their own functions. Instead, in an approach that is much more in line with Data Oriented Programming, components are only for storing data.


Q: When a new component is developed by a community member is there a process for getting the new component approved?

R:


Q: What is the process for checking in a change when the change spans both the unity renderer and the kernel (and perhaps also the explorer)?

R:


Q: We need to build a multi-land test scene. This was easy before with the kernel test-scenes. Is this still possible? Is it documented somewhere?

R: It's possible by using Workspaces. Workspaces allow you to run a preview of multiple Decentralanad projects at the same time. If these are scenes that are near each other, you should see them renedererd in their corresponding locations, in one single preview session. See [the docs](https://docs.decentraland.org/creator/development-guide/workspaces/)


Q: We have a communication protocol. We think it may belong in the Comms part of the kernel. What is the best way to get up to speed on this part of the kernel?

R:


Q: What would you say to those that claim the foundation needs to train the community on taking the reigns when the foundation decides it's time for them to fly?

R: The Foundation's goal is that the community ends up taking the reigns of the project. There have been a number of initiatives to help promote more contributions from the community and with reducing friction in this process.


Q: My experience tends to get worse than when I started in May.  Why are things getting worse rather than better?  Even in empty realms.    Intel 11 i5 IRIS GPU.  

R: There are many ongoing initiatives with regards to performance, the explorer team is constantly working on optimizing the renderer and everything around the experience of players enterind Decentraland. Improving that further is currently one of the key focuses of the Foundation.


Q: Currently one has to press and keep pressing the T keyboard to talk. Does it exit a shortcut to toggle the state talk/mute without keeping pressing T 

R:


Q: How can I reduce the volume of audio track in a VideoTexture in proportional to the distance between audio source and avatar just like the Voice chat 

R: It's currently not possible, Video Streams sound at a constant volume throughout the scene. You could work around that, though, by creating a system that checks the player's distance away from a point, and adjusts the Video Texture's volume on every frame.


Q: Is SDK planned to support loading 3D models from an URL address  

R:


Q: How can I render a Text / Image onto a 2D surface like UIImage but it is not hidden while the keyboard "U" is pressed

R: That's not possible by design. All UI elements on the screen need to be hideable by pressing "U". This is not just to enable taking screenshots, but also to mitigate any malicious use of the UI.


Q: How can I playback a video on a UIImage. As I know UIShape does not support Video texture.

R: It's not currently possible to play Video textures on UI elements. It will be possible on SDK7.


Q: Will there be code modifications required when upgrading a project from sdk 6 to 7?  

R: Yes, the syntax of the new SDK will have multiple differences. This new syntax is fully documenteda and will be published together with the Alpha release. There will be migration guides and other helpful documents in the future.


Q: Will we be able to add custom playable avatars?

R:


Q: Will sdk7 have an upgrade to the ECMA preferably newer than es2018?

R:


Q: How to avoid animation conflicts?

R:


Q: How to add a jump that is slower than the default jump?

R:


Q: How to change the ‚Äústeps‚Äù sound fx for skating sounds? (wheels rolling)

R:


Q: when we can use the SDK to mint, publish and airdrop items and wearables?

R:


Q: Would it be possible to call to your REST API method from our backend (using on our side the seed phrase of the wallet from which we will mint)?

R:


Q: Not technical questions but hope you can help. I am researching the Tokenomics and need help. Mod have helped but still lacking info. Dc id: gcrod#7280 üôè

R:


Q: Agus mentioned that using external content (not in the content layer) is problematic. But isn't that just the same as using an external API?

R:


Q: Is it possible to automate the minting of clothes and sell them to the player through the REST API? We make a lot of fashionable items for players.

R:


Q: Will you decouple the new sdk runtime from the browser? that was the main roadblock we had in the 2d client.

R:


Q: Will you decouple the new sdk runtime from the browser? that was the main roadblock we had in the 2d client.

R:


Q: Will you decouple the new scene runtime from the browser? that was the main roadblock we had in the 2d client.

R:


Q: How far off is DCL protocol 1.0 with documentation for mass uptake of multiple clients? Very excited by this!

R:


Q: Could you discuss on the progress of portables?

R:


Q: I would like to know how to build a Decentraland.app for mac that points to localhost:3000

R:


Q: I am getting high levels of lag in my scenes - up to 50% hiccups. What is the best way to debug performance issues in the SDK

R:


Q: Can you let us use cameraTarget without movePlayerTo() please?

R:


Q: Are you planning to allow us to use /chagerealm function directly via the SDK?

R:


Q: Are there plans/direction to allow us to impact the dynamic skybox of clients directly through the SDK for shading consistency? 

R:


Q: How can I get two .mp4 videos loaded and playing on my scene and the same time? Or click to change? Also where is this recording posted somewhere?

R:


Q: Will the SDK eventually just contain to DCL contract operations and integrations whilst clients adopt the protocol and define the render finish and mechanics?

R:


Q: What stage are we at for the potential rotation of textures of .gltf files from the BIN files? We can only do this manually atm.

R:


Q: On https://market.decentraland.org/lands if I teleport to a district like Aetheria for example.. I can't teleport to a specific co-ordinate.. Can this be fixed?

R:


Q: Have you ever prototyped the syncing of two separate scenes together with CANNON? IE: Can CANNON physics remain consistent over several independent scenes? 

R:


Q: Are there plans to onboard the solutions provided by genesis.city onto the main map of the Decentraland client?

R:


Q: I sent my url to a friend and it doesn't load for him.. He had a 2019 mac laptop with 32gb ram and a decent AMD graphics card.. Any ideas?

R:


Q: The number of Texture in my scene continues increasing even I add and replace the ImageText. Because I didnot call the "garbage collector" explicitly ? 

R:


Q: Are you currently collected bug-feedback, and is there any way the DAO can help in increasing the quality of that feedback?

R:


Q: What is the biggest barrier limiting the speed of the platform, and how can the DAO help in improving that. 

R:


Q: How far are we from a mobile client?

R:


Q: Are you planning to allow us to use /chagerealm function directly via the SDK?

R:


Q: Are there plans/direction to allow us to impact the dynamic skybox of clients directly through the SDK for shading consistency?

R:


Q: Can you let us impact cameraTarget WITHOUT having to use movePlayerTo() pleaseee?

R:


Q: Wen new SDK?R:


R:

